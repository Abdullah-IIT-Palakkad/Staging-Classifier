{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgqQXWoTq1gV"
      },
      "source": [
        "# MODEL\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels1, out_channels2, flatten_size, out_features1,\n",
        "                 out_features2, out_features3, out_features4, out_features5):\n",
        "        super(Model, self).__init__()\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels1, kernel_size= 3, padding = 1)\n",
        "        self.cnn2 = nn.Conv2d(out_channels1, out_channels2, kernel_size= 3, padding = 1)\n",
        "        self.linear1 = nn.Linear(flatten_size, out_features1)\n",
        "        self.linear2 = nn.Linear(out_features1, out_features2)\n",
        "        self.linear3 = nn.Linear(out_features2, out_features3)\n",
        "        self.linear4 = nn.Linear(out_features3, out_features4)\n",
        "        self.linear5 = nn.Linear(out_features4, out_features5)\n",
        "        self.BatchNorm1 = nn.BatchNorm2d(out_channels1)\n",
        "        self.BatchNorm2 = nn.BatchNorm2d(out_channels2)\n",
        "        self.dropout = nn.Dropout2d(0.5)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.average_pool = nn.AvgPool2d(kernel_size=3, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.cnn1(x)\n",
        "        output = self.BatchNorm1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.average_pool(output)\n",
        "        output = self.cnn2(output)\n",
        "        output = self.BatchNorm2(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.average_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear1(output)\n",
        "        output = self.dropout1(output)\n",
        "        output = self.linear2(output)\n",
        "        output = self.dropout1(output)\n",
        "        output = self.linear3(output)\n",
        "        output = self.dropout1(output)\n",
        "        output = self.linear4(output)\n",
        "        output = self.dropout1(output)\n",
        "        output = self.linear5(output)\n",
        "        output = F.softmax(output, dim = 1)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-G6aiRrFn5"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
        "import math\n",
        "import argparse\n",
        "from classification import Model\n",
        "\n",
        "\n",
        "\n",
        "def labeling(label_bf):\n",
        "    label = np.array([])\n",
        "    for i in label_bf:\n",
        "        if i == 1:\n",
        "            new_s = 1\n",
        "        else:\n",
        "            new_s = 2\n",
        "        label = np.append(label, new_s)\n",
        "    return label\n",
        "\n",
        "def label_onehot(label):\n",
        "    onehot_label = np.zeros((len(label), 2))\n",
        "    for i in range(len(label)):\n",
        "        stage = int(label[i] - 1)\n",
        "        onehot_label[i, stage] = 1\n",
        "    return onehot_label\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, images, label):\n",
        "        self.labels = label\n",
        "        self.images = images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.images[index]\n",
        "        y = self.labels[index]\n",
        "        return X, y\n",
        "\n",
        "def training(num_epochs, my_model, criterion, optimizer, train_loader, validation_loader, test_loader, save_root):\n",
        "\n",
        "    result = np.array([]).reshape(0,6)\n",
        "    val_loss_list = np.array([])\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss_train = 0.0\n",
        "        epoch_train_acc = 0.0\n",
        "        predicted_train_output = np.array([])\n",
        "        train_real = np.array([])\n",
        "\n",
        "        train_len = 0\n",
        "        my_model.train()\n",
        "        for train_x_batch, train_y_batch in train_loader:\n",
        "            train_x = Variable(train_x_batch).cuda()\n",
        "            train_y = Variable(train_y_batch).cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_output = my_model(train_x)\n",
        "            train_epoch_loss = criterion(train_output, torch.max(train_y, 1)[1])\n",
        "\n",
        "            train_epoch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss_train += (train_epoch_loss.data.item() * len(train_x_batch))\n",
        "\n",
        "            pred = np.argmax(train_output.data.cpu().numpy(), axis = 1)\n",
        "            true = np.argmax(train_y.data.cpu().numpy(), axis = 1)\n",
        "            predicted_train_output = np.append(predicted_train_output, pred)\n",
        "            train_real = np.append(train_real, true)\n",
        "            train_len += len(train_x_batch)\n",
        "\n",
        "        train_loss = epoch_loss_train / train_len\n",
        "        train_acc = len(np.where(predicted_train_output == train_real)[0]) / len(predicted_train_output)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            '''\n",
        "            validation\n",
        "            '''\n",
        "            epoch_loss_val = 0.0\n",
        "            epoch_acc_val = 0.0\n",
        "            predicted_val_output = np.array([])\n",
        "            val_real = np.array([])\n",
        "\n",
        "            my_model.eval()\n",
        "            val_len = 0\n",
        "            for validation_x_batch, validation_y_batch in validation_loader:\n",
        "                validation_x = Variable(validation_x_batch).cuda()\n",
        "                validation_y = Variable(validation_y_batch).cuda()\n",
        "\n",
        "                validation_output = my_model(validation_x)\n",
        "                validation_epoch_loss = criterion(validation_output, torch.max(validation_y, 1)[1])\n",
        "\n",
        "                epoch_loss_val += (validation_epoch_loss.data.item() * len(validation_x_batch))\n",
        "\n",
        "                pred_val = np.argmax(validation_output.data.cpu().numpy(), axis = 1)\n",
        "                true_val = np.argmax(validation_y.data.cpu().numpy(), axis = 1)\n",
        "                correct_val = len(np.where(pred_val == true_val)[0])\n",
        "                epoch_acc_val += (correct_val / len(pred_val))\n",
        "\n",
        "                predicted_val_output = np.append(predicted_val_output, pred_val)\n",
        "                val_real = np.append(val_real, true_val)\n",
        "                val_len += len(validation_x_batch)\n",
        "\n",
        "\n",
        "            val_loss = epoch_loss_val / val_len\n",
        "            val_acc = len(np.where(predicted_val_output == val_real)[0]) / len(predicted_val_output)\n",
        "\n",
        "            '''\n",
        "            test\n",
        "            '''\n",
        "            epoch_loss_test = 0.0\n",
        "            epoch_acc_test = 0.0\n",
        "            predicted_test_output = np.array([])\n",
        "            test_real = np.array([])\n",
        "\n",
        "            my_model.eval()\n",
        "            test_len = 0\n",
        "\n",
        "            for test_x_batch, test_y_batch in test_loader:\n",
        "                test_x = Variable(test_x_batch).cuda()\n",
        "                test_y = Variable(test_y_batch).cuda()\n",
        "\n",
        "                test_output = my_model(test_x)\n",
        "                test_epoch_loss = criterion(test_output, torch.max(test_y, 1)[1])\n",
        "\n",
        "                epoch_loss_test += (test_epoch_loss.data.item() * len(test_x_batch))\n",
        "\n",
        "                pred_test = np.argmax(test_output.data.cpu().numpy(), axis = 1)\n",
        "                true_test = np.argmax(test_y.data.cpu().numpy(), axis = 1)\n",
        "                correct_test = len(np.where(pred_test == true_test)[0])\n",
        "                epoch_acc_test += (correct_test / len(pred_test))\n",
        "\n",
        "                predicted_test_output = np.append(predicted_test_output, pred_test)\n",
        "                test_real = np.append(test_real, true_test)\n",
        "                test_len += len(test_x_batch)\n",
        "\n",
        "\n",
        "            test_loss = epoch_loss_test / test_len\n",
        "            test_acc = len(np.where(predicted_test_output == test_real)[0]) / len(predicted_test_output)\n",
        "\n",
        "        result_list = [train_loss, train_acc, val_loss, val_acc, test_loss, test_acc]\n",
        "        result = np.append(result, np.array(result_list).reshape(1, 6), axis = 0)\n",
        "\n",
        "        val_loss_list = np.append(val_loss_list, val_loss)\n",
        "\n",
        "        if val_loss_list[epoch] == val_loss_list.min():\n",
        "            print('model_saving ----- epoch : {}, validation_loss : {:.6f}'.format(epoch, val_loss))\n",
        "            torch.save(my_model.state_dict(), save_root + '/classification_checkpoint.pt')\n",
        "\n",
        "        if (epoch + 1) == 1 :\n",
        "            print('Epoch [{}/{}], Train loss : {:.4f}, Train acc : {:.2f}, Val loss : {:.4f}, Val acc : {:.2f}, Test loss : {:.4f}, Test acc : {:.2f}'.\n",
        "                  format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
        "\n",
        "\n",
        "        if (epoch + 1) % 10 == 0 :\n",
        "            print('Epoch [{}/{}], Train loss : {:.4f}, Train acc : {:.2f}, Val loss : {:.4f}, Val acc : {:.2f}, Test loss : {:.4f}, Test acc : {:.2f}'.\n",
        "                  format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
        "\n",
        "    return result\n",
        "\n",
        "def test(my_model, criterion, optimizer, test_loader, save_root):\n",
        "    fname = os.path.join(save_root, 'classification_checkpoint.pt')\n",
        "    checkpoint = torch.load(fname)\n",
        "    my_model.load_state_dict(checkpoint)\n",
        "\n",
        "    print(\"Results for test dataset\")\n",
        "    with torch.no_grad():\n",
        "        '''\n",
        "        test\n",
        "        '''\n",
        "        epoch_loss_test = 0.0\n",
        "        epoch_acc_test = 0.0\n",
        "        predicted_test_output = np.array([])\n",
        "        test_probability = np.array([]).reshape(0, 2)\n",
        "        test_real = np.array([])\n",
        "\n",
        "        my_model.eval()\n",
        "        test_len = 0\n",
        "\n",
        "        for test_x_batch, test_y_batch in test_loader:\n",
        "            test_x = Variable(test_x_batch).cuda()\n",
        "            test_y = Variable(test_y_batch).cuda()\n",
        "\n",
        "            test_output = my_model(test_x)\n",
        "            test_epoch_loss = criterion(test_output, torch.max(test_y, 1)[1])\n",
        "\n",
        "            epoch_loss_test += (test_epoch_loss.data.item() * len(test_x_batch))\n",
        "\n",
        "            pred_test = np.argmax(test_output.data.cpu().numpy(), axis = 1)\n",
        "            true_test = np.argmax(test_y.data.cpu().numpy(), axis = 1)\n",
        "            correct_test = len(np.where(pred_test == true_test)[0])\n",
        "            epoch_acc_test += (correct_test / len(pred_test))\n",
        "            test_probability = np.append(test_probability, test_output.detach().data.cpu().numpy(), axis = 0)\n",
        "\n",
        "            predicted_test_output = np.append(predicted_test_output, pred_test)\n",
        "            test_real = np.append(test_real, true_test)\n",
        "            test_len += len(test_x_batch)\n",
        "\n",
        "\n",
        "        test_loss = epoch_loss_test / test_len\n",
        "        test_acc = len(np.where(predicted_test_output == test_real)[0]) / len(predicted_test_output)\n",
        "        test_auc = roc_auc_score(test_real, test_probability[:, 1])\n",
        "    print('Test loss : {:.4f}, Test Accuracy : {:.4f}, Test AUC : {:.4f}'.format(test_loss, test_acc, test_auc))\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--data_root\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--save_root\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--batch_size\",\n",
        "        default=16,\n",
        "        type=int,\n",
        "        required=False,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--learning_rate\",\n",
        "        default=1e-6,\n",
        "        type=float,\n",
        "        required=False,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--num_epochs\",\n",
        "        default=500,\n",
        "        type=int,\n",
        "        required=False,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--parms\",\n",
        "        nargs = '+',\n",
        "        help=\"delimited list input\",\n",
        "        type=int\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    training_latent_variable = np.load(args.data_root + '/training_latent_variable_noBatchNorm.npy')\n",
        "    training_label_bf = np.load(args.data_root + '/training_latent_variable_stage_noBatchNorm.npy')\n",
        "    validation_latent_variable = np.load(args.data_root + '/validation_latent_variable_noBatchNorm.npy')\n",
        "    validation_label_bf = np.load(args.data_root + '/validation_latent_variable_stage_noBatchNorm.npy')\n",
        "    test_latent_variable = np.load(args.data_root + '/test_latent_variable_noBatchNorm.npy')\n",
        "    test_label_bf = np.load(args.data_root + '/test_latent_variable_stage_noBatchNorm.npy')\n",
        "\n",
        "    training_label = labeling(training_label_bf)\n",
        "    validation_label = labeling(validation_label_bf)\n",
        "    test_label = labeling(test_label_bf)\n",
        "\n",
        "    train_label = label_onehot(training_label)\n",
        "    val_label = label_onehot(validation_label)\n",
        "    te_label = label_onehot(test_label)\n",
        "\n",
        "\n",
        "    train_x = training_latent_variable.astype('float16')\n",
        "    train_y = train_label\n",
        "    val_x = validation_latent_variable.astype('float16')\n",
        "    val_y = val_label\n",
        "    test_x = test_latent_variable.astype('float16')\n",
        "    test_y = te_label\n",
        "\n",
        "    train_x_tr = torch.from_numpy(train_x).type(torch.FloatTensor)\n",
        "    train_y_tr = torch.from_numpy(train_y).type(torch.LongTensor)\n",
        "    val_x_tr = torch.from_numpy(val_x).type(torch.FloatTensor)\n",
        "    val_y_tr = torch.from_numpy(val_y).type(torch.LongTensor)\n",
        "    test_x_tr = torch.from_numpy(test_x).type(torch.FloatTensor)\n",
        "    test_y_tr = torch.from_numpy(test_y).type(torch.LongTensor)\n",
        "\n",
        "    training_set = Dataset(train_x_tr, train_y_tr)\n",
        "    train_loader = DataLoader(training_set, batch_size = args.batch_size, shuffle=True)\n",
        "    batch_len_train = len(train_loader)\n",
        "\n",
        "    validation_set = Dataset(val_x_tr, val_y_tr)\n",
        "    validation_loader = DataLoader(validation_set, batch_size = args.batch_size, shuffle=True)\n",
        "    batch_len_val = len(validation_loader)\n",
        "\n",
        "    test_set = Dataset(test_x_tr, test_y_tr)\n",
        "    test_loader = DataLoader(test_set, batch_size = 1, shuffle = True)\n",
        "    batch_len_test = len(test_loader)\n",
        "\n",
        "    parms = args.parms\n",
        "\n",
        "    flatten_size = parms[1] * 4 * 4\n",
        "\n",
        "    my_model = Model(512, parms[0], parms[1], flatten_size, parms[2], parms[3], parms[4], parms[5], 2)\n",
        "    my_model.cuda();\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(my_model.parameters(), lr=args.learning_rate, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "    result = training(args.num_epochs, my_model, criterion, optimizer, train_loader, validation_loader, test_loader, args.save_root)\n",
        "    test(my_model, criterion, optimizer, test_loader, args.save_root)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}